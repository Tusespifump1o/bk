// rdso/rdso.go
// Copyright(c) 2017 Matt Pharr
// BSD licensed; see LICENSE for details.

// Simple APIs to apply Reed-Solomon encoding to files, based on
// github.com/klauspost/reedsolomon. Provides facilities to check the
// integrity of encoded files and to recover corrupt files.

package rdso

import (
	"encoding/gob"
	"errors"
	"github.com/klauspost/reedsolomon"
	u "github.com/mmp/bk/util"
	"golang.org/x/crypto/sha3"
	"io"
)

var ErrFileCorrupt = errors.New("File corrupted")

var ErrSizeIncorrect = errors.New("Provided size didn't match count of bytes read")

// hashSize is the number of bytes in the hash values returned to
// represent blobs of data.
const hashSize = 32

// Hash encodes a fixed-size secure hash of a collection of bytes.
type hash [hashSize]byte

// hashBytes computes the SHAKE256 hash of the given byte slice.
func hashBytes(b []byte) hash {
	var h hash
	sha3.ShakeSum256(h[:], b)
	return h
}

// The .rs file format starts with an rsFileHeader and then has a series of
// rsFileSegments, all gob encoded.
type rsFileHeader struct {
	// Size of the original file
	FileSize                   int64
	NDataShards, NParityShards int
	HashRate                   int
}

// Each segment of bytes in the input file (of length NDataShards *
// HashRate) is represented by an rsFileSegment.
type rsFileSegment struct {
	Hashes       []hash // First data, then parity hashes
	ParityShards [][]byte
}

// Encode Reed-Solomon encodes the bytestream from the io.Reader r and
// write the result to the provided io.Writer.  The number of bytes that
// will be provided by r must be passed in the size argument.
func Encode(r io.ReadSeeker, size int64, w io.Writer, nDataShards, nParityShards, hashRate int) error {
	// Create the gob encoder and write the header.
	genc := gob.NewEncoder(w)
	if err := genc.Encode(rsFileHeader{
		FileSize:      size,
		NDataShards:   nDataShards,
		NParityShards: nParityShards,
		HashRate:      hashRate}); err != nil {
		return err
	}

	rsenc, err := reedsolomon.New(nDataShards, nParityShards)
	if err != nil {
		return err
	}

	sumSize := int64(0)
	buf := make([]byte, nDataShards*hashRate)
	for {
		n, err := io.ReadFull(r, buf)
		sumSize += int64(n)

		if err == io.EOF {
			break
		} else if err != nil && err != io.ErrUnexpectedEOF {
			// ErrUnexpectedEOF is fine; it's just a partial segment at the
			// end of the file.
			return err
		}

		// Split the segment into file shards and allocate empty parity
		// shards.
		shards, err := rsenc.Split(buf[:n])
		if err != nil {
			return err
		}

		// Reed-Solomon encode the current segment.
		if err = rsenc.Encode(shards); err != nil {
			return err
		}

		// Sanity check the results.
		if ok, err := rsenc.Verify(shards); !ok || err != nil {
			panic("verify failed after encoding")
		}

		// Compute data and parity hashes and initialize the rsFileSegment.
		var seg rsFileSegment
		for _, s := range shards {
			seg.Hashes = append(seg.Hashes, hashBytes(s))
		}
		seg.ParityShards = shards[nDataShards:]

		// Add the segment to the .rs file
		if err = genc.Encode(seg); err != nil {
			return err
		}
	}

	if sumSize != size {
		return ErrSizeIncorrect
	}
	return nil
}

// Utility routine that calls the given callback function for each segment
// in the data from r, providing the shards (file and parity) and hash
// values.
func forEachSegment(r, rsr io.Reader, log *u.Logger,
	callback func(h rsFileHeader, hashes []hash, shards [][]byte) error) error {
	var h rsFileHeader
	d := gob.NewDecoder(rsr)
	if err := d.Decode(&h); err != nil {
		return err
	}

	rsenc, err := reedsolomon.New(h.NDataShards, h.NParityShards)
	if err != nil {
		return err
	}

	sumSize := int64(0)
	buf := make([]byte, h.NDataShards*h.HashRate)
	for {
		n, err := io.ReadFull(r, buf)
		sumSize += int64(n)

		if err == io.EOF {
			// Make sure we're at EOF for the .rs file as well
			var seg rsFileSegment
			if err = d.Decode(&seg); err != io.EOF {
				return errors.New("Extra data found at end of .rs file")
			}
			break
		} else if err != nil && err != io.ErrUnexpectedEOF {
			return err
		}

		shards, err := rsenc.Split(buf[:n])
		if err != nil {
			return err
		}

		var seg rsFileSegment
		if err = d.Decode(&seg); err != nil {
			return err
		}

		// Put the data and parity together in shards.
		copy(shards[h.NDataShards:], seg.ParityShards)

		if err = callback(h, seg.Hashes, shards); err != nil {
			return err
		}
	}

	if sumSize != h.FileSize {
		return ErrSizeIncorrect
	}
	return nil
}

// Check the integrity of the bytestream from r using an encoding
// bytestream in rsr that was been generated by Encode().
func Check(r, rsr io.Reader, log *u.Logger) error {
	nErrors := 0
	seg := 0
	err := forEachSegment(r, rsr, log,
		func(h rsFileHeader, hashes []hash, shards [][]byte) error {
			for i, s := range shards {
				if hashBytes(s) != hashes[i] {
					nErrors++
					if i < h.NDataShards {
						log.Warning("data segment %d shard %d hash mismatch", seg, i)
					} else {
						log.Warning("parity segment %d shard %d hash mismatch", seg,
							i-h.NDataShards)
					}
				}
			}
			seg++
			return nil
		})

	if err != nil {
		return err
	}
	if nErrors > 0 {
		return ErrFileCorrupt
	}
	return nil
}

// Given a bytestream r and its encoding in rsr, attempt to repair any
// corrupt bytes, returning a repaired bytestream in w and a repaired
// encoding bytestream in rsw.  Returns nil iff recovery was successful.
func Restore(r, rsr io.Reader, size int64, w, rsw io.Writer, log *u.Logger) error {
	genc := gob.NewEncoder(rsw)
	w = &limitedWriter{w, size}

	first := true
	err := forEachSegment(r, rsr, log,
		func(h rsFileHeader, hashes []hash, shards [][]byte) error {
			if first {
				// First segment; now have the header, so can write the
				// header to the recovered RS file.
				if err := genc.Encode(h); err != nil {
					return err
				}
				first = false
			}

			reconstruct := false
			for i, s := range shards {
				if hashBytes(s) != hashes[i] {
					shards[i] = nil
					reconstruct = true
				}
			}

			if reconstruct {
				rsenc, err := reedsolomon.New(h.NDataShards, h.NParityShards)
				if err != nil {
					return err
				}

				if err := rsenc.Reconstruct(shards); err != nil {
					return err
				}
				if ok, err := rsenc.Verify(shards); !ok || err != nil {
					panic("verify failed")
				}

				// Double check that the reconstructed hashes match.
				for i, s := range shards {
					if hashBytes(s) != hashes[i] {
						log.Warning("Reconstructed file contents still don't match hash. Though, this could mean the hash was corrupted...")
					}
				}
			}

			// Write to the recovered data file..
			for _, s := range shards[:h.NDataShards] {
				if _, err := w.Write(s); err != nil {
					return err
				}
			}

			// ..and to the recovered rs file.
			seg := rsFileSegment{hashes, shards[h.NDataShards:]}
			if err := genc.Encode(seg); err != nil {
				return err
			}
			return nil
		})

	return err
}

// Write no more than N bytes to W.
type limitedWriter struct {
	W io.Writer
	N int64
}

func (w *limitedWriter) Write(data []byte) (int, error) {
	if int64(len(data)) > w.N {
		data = data[:w.N]
	}
	n, err := w.W.Write(data)
	w.N -= int64(n)
	return n, err
}
